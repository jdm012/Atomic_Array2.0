{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedd7456",
   "metadata": {},
   "source": [
    "# Evaluating Atomic Array Representations with Attention Mechanisms for Bandgap Prediction and Classification\n",
    "This notebook applies attention-based deep learning to atomic array representations for bandgap prediction and classification.\n",
    "\n",
    "- Atomic arrays encode crystal structures into tensors.\n",
    "\n",
    "- Attention layers highlight relevant atomic interactions for accurate and interpretable predictions.\n",
    "\n",
    "The goal is to benchmark self attention-enhanced deep learning models in materials materials property prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8920047",
   "metadata": {
    "executionInfo": {
     "elapsed": 10955,
     "status": "ok",
     "timestamp": 1726096468967,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "b8920047"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "initializer_seed = 10\n",
    "initializer_scale = 1e-2\n",
    "\n",
    "kernel_initializer = tf.keras.initializers.VarianceScaling(scale = initializer_scale, distribution = 'normal', seed = initializer_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c400c33",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1726096468968,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "2c400c33"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d3697",
   "metadata": {},
   "source": [
    "#### Atomic Array definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185b96a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7031,
     "status": "ok",
     "timestamp": 1726096532434,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "5185b96a",
    "outputId": "7c21a0c9-a3bb-44bf-e932-443c383cdd64"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('support/hseDataset.pkl')\n",
    "x = np.load('data/inputs.npy')\n",
    "y = np.load('data/outputs.npy')\n",
    "\n",
    "print(df.shape, x.shape)\n",
    "\n",
    "x[:,:,:3] = (x[:,:,:3] - np.median(x[:,:,:3], axis=1, keepdims=True))\n",
    "\n",
    "### Materials with 1 < Z <= 84\n",
    "idx = np.intersect1d(np.argwhere((x[:,:,-1] > 0).sum(axis=1) == 512)[:,0], np.argwhere((x[:,:,-1] <= 84).sum(axis=1) == 512)[:,0])\n",
    "x = x[idx]\n",
    "y = y[idx]\n",
    "df = df.iloc[idx,:].reset_index(drop=True)\n",
    "\n",
    "### Band gap filtering (Up to two standard deviations)\n",
    "n = 2\n",
    "\n",
    "conditions = dict()\n",
    "for row in range(4):\n",
    "    conditions[row] = np.intersect1d(np.argwhere(0 < y[:,row])[:,0], np.argwhere(y[:,row] <= y[:,row].mean() + n*y[:,row].std())[:,0])\n",
    "idxRightOutputs = np.intersect1d(np.intersect1d(conditions[0], conditions[1]), np.intersect1d(conditions[2], conditions[3]))\n",
    "\n",
    "### Gap type (Just Direct or Indirect)\n",
    "idxRightOutputs = np.intersect1d(idxRightOutputs, np.argwhere(y[:,4] == y[:,5])[:,0])\n",
    "\n",
    "x = x[idxRightOutputs]\n",
    "y = y[idxRightOutputs, :5]\n",
    "df = df.iloc[idxRightOutputs,:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67e596",
   "metadata": {
    "id": "8b67e596"
   },
   "source": [
    "#### Training and Test set construction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00341340",
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1726096535540,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "00341340"
   },
   "outputs": [],
   "source": [
    "testFrac = 0.20\n",
    "muestras = x.shape[0]\n",
    "\n",
    "idxtest = np.random.choice(range(muestras), int(testFrac*muestras), replace=False)\n",
    "idxtrain = np.setdiff1d(np.arange(muestras), idxtest)\n",
    "\n",
    "xtrain = x[idxtrain]\n",
    "ytrain = y[idxtrain]\n",
    "\n",
    "xtest = x[idxtest]\n",
    "ytest = y[idxtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3277d",
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1726096538298,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "4da3277d"
   },
   "outputs": [],
   "source": [
    "def data_augmentation(x, y):\n",
    "\n",
    "    xtemp1 = np.zeros(x.shape)\n",
    "    for row in range(x.shape[0]):\n",
    "        xtemp1[row] = x[row,np.lexsort((x[row,:,0], x[row,:,1], x[row,:,2]))]\n",
    "\n",
    "    xtemp2 = np.zeros(x.shape)\n",
    "    for row in range(x.shape[0]):\n",
    "        xtemp2[row] = x[row,np.lexsort((x[row,:,2], x[row,:,1], x[row,:,0]))]\n",
    "\n",
    "    xtemp3 = np.zeros(x.shape)\n",
    "    for row in range(x.shape[0]):\n",
    "        xtemp3[row] = x[row,np.lexsort((x[row,:,0], x[row,:,2], x[row,:,1]))]\n",
    "\n",
    "    xtemp4 = np.zeros(x.shape)\n",
    "    for row in range(x.shape[0]):\n",
    "        xtemp4[row] = x[row,np.lexsort((x[row,:,1], x[row,:,2], x[row,:,0]))]\n",
    "\n",
    "    xtemp5 = np.zeros(x.shape)\n",
    "    for row in range(x.shape[0]):\n",
    "        xtemp5[row] = x[row,np.lexsort((x[row,:,1], x[row,:,0], x[row,:,2]))]\n",
    "\n",
    "    xtemp6 = np.zeros(x.shape)\n",
    "    for row in range(x.shape[0]):\n",
    "        xtemp6[row] = x[row,np.lexsort((x[row,:,2], x[row,:,0], x[row,:,1]))]\n",
    "\n",
    "    return np.concatenate((xtemp1, xtemp2, xtemp3, xtemp4, xtemp5, xtemp6), axis=0), np.concatenate((y,y,y,y,y,y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255a74b",
   "metadata": {
    "executionInfo": {
     "elapsed": 5470,
     "status": "ok",
     "timestamp": 1726096546547,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "d255a74b"
   },
   "outputs": [],
   "source": [
    "xtrain, ytrain = data_augmentation(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35205cc2",
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1726096546787,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "35205cc2"
   },
   "outputs": [],
   "source": [
    "for row in range(xtest.shape[0]):\n",
    "    xtest[row] = xtest[row, np.lexsort((xtest[row,:,0], xtest[row,:,1], xtest[row,:,2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Band-gap type\n",
    "#bg=pd.DataFrame(ytest)\n",
    "#bg[4].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57cc4a",
   "metadata": {
    "id": "2c57cc4a"
   },
   "source": [
    "#### Training set randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485b04c",
   "metadata": {
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1726096547036,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "d485b04c"
   },
   "outputs": [],
   "source": [
    "idxBarajeo = np.random.choice(range(xtrain.shape[0]), xtrain.shape[0], replace=False)\n",
    "idxBarajeo = np.random.choice(idxBarajeo, xtrain.shape[0], replace=False)\n",
    "idxBarajeo = np.random.choice(idxBarajeo, xtrain.shape[0], replace=False)\n",
    "\n",
    "xtrain = xtrain[idxBarajeo]\n",
    "ytrain = ytrain[idxBarajeo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37dbfe7",
   "metadata": {},
   "source": [
    "#### Attention Mechanism-based DL Architectures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da378582",
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1726096549799,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "da378582"
   },
   "outputs": [],
   "source": [
    "def create_set(tensors = list):\n",
    "\n",
    "    dtensors = list()\n",
    "    for i in tensors:\n",
    "        dtensors += [tf.data.Dataset.from_tensor_slices(i)]\n",
    "    dtensors = tuple(dtensors)\n",
    "    return tf.data.Dataset.zip(dtensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ca6f7",
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1726096552066,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "e70ca6f7"
   },
   "outputs": [],
   "source": [
    "class ProcessTensor(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(ProcessTensor, self).__init__()\n",
    "\n",
    "    def call(self, x, random):\n",
    "        indices = tf.cast(x[:,:,-1], dtype=tf.int32)\n",
    "        xelem = tf.gather(random, indices, batch_dims=1)\n",
    "        return tf.concat((x[:,:,:-1], xelem), axis=-1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ProcessTensor, self).get_config()\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AK0J_z-fWrd7",
   "metadata": {
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1726097085200,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "AK0J_z-fWrd7"
   },
   "outputs": [],
   "source": [
    "def ConvLayer(x, filters = 32, filter_size=4, kernel_initializer = kernel_initializer,\n",
    "              activation='', dropout=0.0):\n",
    "\n",
    "    \"\"\"\n",
    "    This function performs a convolution on a tensorflow tensor without reducing its original dimensionality;\n",
    "    i.e., the provided tensor is padded to keep the original dimension. After the convolution,\n",
    "    the operations Batch Normalization, Activation, and Dropout are performed.\n",
    "    Parameters:\n",
    "        x: a tensorflow tensor of shape (batch_size, length, feature_maps)\n",
    "        filters: the number of feature maps of the convolved tensor.\n",
    "        filter_size: the length of the feature maps.\n",
    "        kernel_initializer: an object from the module keras initializers.\n",
    "                        It sets how the parameters are intialized at the beginning of the optimization.\n",
    "        activation: string, the activation function to use after the convolutional part.\n",
    "        dropout: the dropout fraction.\n",
    "        stage: a number to keep control on the name of the layers in the CNN architecture.\n",
    "    Returns:\n",
    "        x: a processed (convolved) tensorflow tensor of shape (batch_size, length, feature_maps)\n",
    "        int(stage) + 1: a number that keeps the serialization of the layers in the CNN architecture\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(filters = filters, kernel_size = filter_size,\n",
    "                      padding = 'same', kernel_initializer=kernel_initializer,\n",
    "                      bias_initializer=\"zeros\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    if activation:\n",
    "        if activation == 'leaky_relu': x = tf.keras.layers.LeakyReLU(0.15)(x)\n",
    "        else: x = tf.keras.layers.Activation(activation)(x)\n",
    "\n",
    "    if dropout:\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def ResBlock(x, filters = 32, fsize_main = 4, fsize_sc = 1, kernel_initializer=kernel_initializer,\n",
    "             activation='', dropout=0.0, chain = 2):\n",
    "    \"\"\"\n",
    "    This function creates a residual block using the defined function above 'ConvLayer'.\n",
    "    The depth of the residual block (number of functions ConvLayer) is controlled with\n",
    "    the parameter chain.\n",
    "    This function does not reduce the dimensionality of the original tensor.\n",
    "    If the number of feature maps changes in the main path a ConvLayer is performed in the secondary path,\n",
    "    otherwise the original tensor is simply added with the processed one.\n",
    "\n",
    "    Parameters:\n",
    "        x: a tensorflow tensor of shape (batch_size, length, feature_maps)\n",
    "        filters: the number of feature maps of the convolved tensor.\n",
    "        fsize_main: the length of the feature maps in the main path.\n",
    "        fsize_sc: the length of the feature maps in the secondary path.\n",
    "        kernel_initializer: an object from the module keras initializers.\n",
    "                        It sets how the parameters are intialized at the beginning of the optimization.\n",
    "        activation: string, the activation function to use after the convolutional part.\n",
    "        dropout: the dropout fraction.\n",
    "        stage: a number to keep control on the name of the layers in the CNN architecture.\n",
    "        chain: this parameter defines the depth of the main path.\n",
    "    Returns:\n",
    "        x: a processed (convolved) tensorflow tensor of shape (batch_size, length, feature_maps)\n",
    "        int(stage) + 1: a number that keeps the serialization of the layers in the CNN architecture\n",
    "    \"\"\"\n",
    "    x_shortcut = x\n",
    "\n",
    "    for depth in range(chain):\n",
    "\n",
    "        if depth%2 == 0:\n",
    "            x = ConvLayer(x, filters = filters, filter_size = fsize_main,\n",
    "                                  kernel_initializer = kernel_initializer,\n",
    "                                  activation = activation, dropout=dropout)\n",
    "        else:\n",
    "            x = ConvLayer(x, filters = filters, filter_size = fsize_main,\n",
    "                                  kernel_initializer = kernel_initializer,\n",
    "                                  dropout=dropout)\n",
    "\n",
    "    if x_shortcut.shape[-1] != x.shape[-1]:\n",
    "        x_shortcut = ConvLayer(x_shortcut, filters = filters, filter_size = fsize_sc,\n",
    "                                       kernel_initializer = kernel_initializer,\n",
    "                                       dropout=(fsize_sc/fsize_main)*dropout)\n",
    "\n",
    "    x = tf.keras.layers.Add()([x, x_shortcut])\n",
    "\n",
    "    if activation:\n",
    "        if activation == 'leaky_relu': x = tf.keras.layers.LeakyReLU(0.15)(x)\n",
    "        else: x = tf.keras.layers.Activation(activation)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b8f51",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1726097085417,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "6e7b8f51"
   },
   "outputs": [],
   "source": [
    "def ResDense(x, units=[1], dropout = 0.25, activation='leaky_relu'):\n",
    "\n",
    "    ldim = x.shape[-1]\n",
    "\n",
    "    for n, unit in enumerate(units):\n",
    "        unit=int(unit)\n",
    "        dense_layer = tf.keras.layers.Dense(unit, kernel_initializer = kernel_initializer)\n",
    "\n",
    "        if n == 0: xm = dense_layer(x)\n",
    "        else: xm = dense_layer(xm)\n",
    "\n",
    "        if n != len(units)-1:\n",
    "\n",
    "            if activation == 'leaky_relu':\n",
    "                xm = tf.keras.layers.LeakyReLU(0.15)(xm)\n",
    "            else:\n",
    "                xm = tf.keras.layers.Activation(activation)(xm)\n",
    "            xm = tf.keras.layers.LayerNormalization()(xm)\n",
    "\n",
    "        if dropout: xm = tf.keras.layers.Dropout(dropout)(xm)\n",
    "\n",
    "    if unit != ldim:\n",
    "        sc_dense_layer = tf.keras.layers.Dense(unit, kernel_initializer = kernel_initializer)\n",
    "\n",
    "        xs = sc_dense_layer(x)\n",
    "\n",
    "        if dropout: xs = tf.keras.layers.Dropout(dropout)(xs)\n",
    "\n",
    "        x = tf.keras.layers.Add()([xm,xs])\n",
    "    else:\n",
    "        x = tf.keras.layers.Add()([xm, x])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c5015e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1726097085893,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "16c5015e"
   },
   "outputs": [],
   "source": [
    "def EncBlock(xenc = tf.Tensor, heads = 1, kernel_initializer = kernel_initializer, dropout = 0, activation = '', units = [1,1]):\n",
    "    xmhaenc = tf.keras.layers.MultiHeadAttention(num_heads = heads, key_dim = xenc.shape[-1]//heads, value_dim = xenc.shape[-1]//heads, kernel_initializer = kernel_initializer, dropout = dropout)(xenc,xenc)\n",
    "    xenc = tf.keras.layers.Add()([xenc, xmhaenc]) #xenc + xmhaenc\n",
    "    xenc = tf.keras.layers.LayerNormalization()(xenc)\n",
    "\n",
    "    xenc = ResDense(xenc, units = [xenc.shape[-1]*i for i in units], dropout = dropout, activation = activation)\n",
    "    xenc = tf.keras.layers.LayerNormalization()(xenc)\n",
    "\n",
    "    return xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    input_tensor = tf.keras.Input((512, 4))\n",
    "    input_tensor2 = tf.keras.Input((96, 100))\n",
    "\n",
    "    x = ProcessTensor()(input_tensor, input_tensor2) #(batch, 512, 103)\n",
    "\n",
    "    x = ResDense(input_tensor, units = [2*64, 64], dropout=0.25, activation='leaky_relu')\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.15)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Permute((2,1))(x)\n",
    "\n",
    "    x = ResDense(x, units=[2*64, 64], dropout=0.25, activation='leaky_relu')\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.15)(x)\n",
    "\n",
    "    for block, hl in enumerate([[2,1],[0.25, 0.125]]):\n",
    "        x = EncBlock(xenc = x, heads = 8, kernel_initializer = kernel_initializer, dropout = 0.25, activation = 'relu', units = hl)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    x = ResDense(x, units = [64, 32], dropout = 0.25, activation='leaky_relu')\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.15)(x)\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(5)(x)\n",
    "\n",
    "    return tf.keras.models.Model(inputs = [input_tensor, input_tensor2], outputs = output_layer, name='nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    input_tensor = tf.keras.Input((512, 4))\n",
    "    input_tensor2 = tf.keras.Input((96, 100))\n",
    "\n",
    "    x = ProcessTensor()(input_tensor, input_tensor2) #(batch, 512, 103)\n",
    "\n",
    "    x = ResDense(input_tensor, units = [10*512, 64], dropout=0.25, activation='leaky_relu')\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.15)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Permute((2,1))(x)\n",
    "\n",
    "    x = ResDense(x, units=[10*512, 512], dropout=0.25, activation='leaky_relu')\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.15)(x)\n",
    "\n",
    "    for block, hl in enumerate([[5,1],[5,1],[5,1],[5,1],[5,1], [5,1],[0.25, 0.125]]):\n",
    "        x = EncBlock(xenc = x, heads = 8, kernel_initializer = kernel_initializer, dropout = 0.25, activation = 'relu', units = hl)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    x = ResDense(x, units = [2048, 512], dropout = 0.25, activation='leaky_relu')\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU(0.15)(x)\n",
    "\n",
    "    output_layer = tf.keras.layers.Dense(5)(x)\n",
    "\n",
    "    return tf.keras.models.Model(inputs = [input_tensor, input_tensor2], outputs = output_layer, name='nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2faa55f",
   "metadata": {
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1726097088631,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "a2faa55f"
   },
   "outputs": [],
   "source": [
    "# Model building/loading\n",
    "nn = model()\n",
    "#nn = tf.keras.models.load_model('nn_conv_23_2sd.keras', custom_objects={'ProcessTensor': ProcessTensor},compile=False)\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f6f27",
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1726097149399,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "e23f6f27"
   },
   "outputs": [],
   "source": [
    "def loss_function(yreal = tf.Tensor, ypred = tf.Tensor):\n",
    "\n",
    "    yrgaps = yreal[:,:-1]\n",
    "    yrtype = yreal[:,-1]\n",
    "\n",
    "    ypgaps = ypred[:,:-1]\n",
    "    yptype = ypred[:,-1]\n",
    "\n",
    "    loss_gaps = tf.keras.losses.LogCosh()(yrgaps, ypgaps)\n",
    "    loss_type = tf.keras.losses.BinaryCrossentropy(from_logits=True)(yrtype, yptype)\n",
    "\n",
    "    return loss_gaps + loss_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bcf35",
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1726097168199,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "fa2bcf35"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e966b56",
   "metadata": {
    "executionInfo": {
     "elapsed": 2106,
     "status": "ok",
     "timestamp": 1726097170986,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "3e966b56"
   },
   "outputs": [],
   "source": [
    "trainset = create_set(tensors = [xtrain, ytrain])\n",
    "testset = create_set(tensors = [xtest, ytest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ade1a",
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1726097195219,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "1b3ade1a"
   },
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85d7f0",
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1726097195988,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "4d85d7f0"
   },
   "outputs": [],
   "source": [
    "trainset = trainset.shuffle(200000, seed = 3451, reshuffle_each_iteration=True)\n",
    "trainset = trainset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "testset = testset.shuffle(200000, seed = 3451, reshuffle_each_iteration=True)\n",
    "testset = testset.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29abe6",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1726097196648,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "9c29abe6"
   },
   "outputs": [],
   "source": [
    "num_epochs=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3403f14",
   "metadata": {
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1726097197713,
     "user": {
      "displayName": "Juan Ivan GOMEZ PERALTA",
      "userId": "18389404996168966303"
     },
     "user_tz": 360
    },
    "id": "e3403f14"
   },
   "outputs": [],
   "source": [
    "random = tf.random.uniform(minval=-1,maxval=1,shape=(96,96))\n",
    "\n",
    "econf = np.load('data/econf.npy', allow_pickle=True).item()\n",
    "\n",
    "xeconf = np.zeros((96,4))\n",
    "for el in range(96):\n",
    "    xeconf[el] = econf[el+1]\n",
    "\n",
    "xeconf = tf.cast(xeconf, dtype = tf.float32)\n",
    "xeconf = tf.concat((xeconf, random), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fba93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTensor(x, y, random):\n",
    "    x = tf.cast(x, dtype=tf.float32)\n",
    "    y = tf.cast(y, dtype = tf.float32)\n",
    "    xelem = tf.one_hot(tf.cast(x[:,:,-1], dtype = tf.int32), depth=96)\n",
    "    xelem = tf.cast(xelem, dtype=tf.float32)\n",
    "    #xelem = xelem @ random\n",
    "    x = tf.concat((x[:,:,:3], xelem), axis=-1)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b475a59",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8d12c",
   "metadata": {
    "id": "d1b8d12c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = list()\n",
    "all_train_losses = list()\n",
    "all_test_losses = list()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "\n",
    "    epoch_losses = list()\n",
    "    for i, (x, y) in enumerate(trainset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            ypred = nn([x, tf.repeat(xeconf[None,...], batch_size, axis=0)], training=True)\n",
    "            loss = loss_function(y, ypred)\n",
    "            \n",
    "        grad = tape.gradient(loss, nn.trainable_variables)\n",
    "        optimizer.apply_gradients(grads_and_vars = zip(grad, nn.trainable_variables))\n",
    "        epoch_losses += [loss.numpy()]\n",
    "        print(i, loss.numpy())\n",
    "    mean_epoch_loss = np.asarray(epoch_losses).mean()\n",
    "    all_train_losses += [mean_epoch_loss]\n",
    "\n",
    "    test_losses = tf.TensorArray(tf.float32, size = len(testset))\n",
    "    for i, (xtest, ytest) in enumerate(testset):\n",
    "        ptest = nn([xtest, tf.repeat(xeconf[None,...], batch_size, axis=0)], training = False)\n",
    "        loss = loss_function(ytest, ptest)\n",
    "\n",
    "        test_losses = test_losses.write(i, loss)\n",
    "\n",
    "    test_losses = test_losses.stack()\n",
    "    mean_test_loss = tf.reduce_mean(test_losses).numpy()\n",
    "    all_test_losses += [mean_test_loss]\n",
    "\n",
    "    print('Epoch', epoch, ' | Training loss:', mean_epoch_loss ,' | Test loss: ', mean_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='nn_conv_27_2sd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f272a",
   "metadata": {
    "id": "745f272a"
   },
   "outputs": [],
   "source": [
    "dftrain = df.iloc[idxtrain,:].reset_index(drop=True)\n",
    "dftest = df.iloc[idxtest,:].reset_index(drop=True)\n",
    "\n",
    "dftrain.to_csv(f'data/dftrain_{model_name}.csv')\n",
    "dftest.to_csv(f'data/dftest__{model_name}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8da8d",
   "metadata": {
    "id": "88f8da8d",
    "outputId": "6459e384-9955-4dd6-b831-7412cfcf3dab"
   },
   "outputs": [],
   "source": [
    "nn.save(f'models/{model_name}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf714b6",
   "metadata": {
    "id": "1bf714b6",
    "outputId": "dc302432-1bb3-4184-b8b6-1195f6e4a198"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(np.arange(num_epochs), all_train_losses, s=10, color='blue', label='training')\n",
    "plt.scatter(np.arange(num_epochs), all_test_losses, s=10, color='red', label='test')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de6fc3",
   "metadata": {
    "id": "22de6fc3"
   },
   "outputs": [],
   "source": [
    "np.save('data/element_codification', xeconf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10869ed9",
   "metadata": {
    "id": "10869ed9"
   },
   "outputs": [],
   "source": [
    "losses_diccio = dict()\n",
    "losses_diccio['train'] = all_train_losses\n",
    "losses_diccio['test'] = all_test_losses\n",
    "pd.DataFrame(losses_diccio).to_csv(f'data/{model_name}_losses.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0339dc",
   "metadata": {
    "id": "fb0339dc"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a6712",
   "metadata": {
    "id": "2a0a6712"
   },
   "outputs": [],
   "source": [
    "x = np.load('data/inputs.npy')\n",
    "y = np.load('data/outputs.npy')\n",
    "df = pd.read_pickle('support/hseDataset.pkl')\n",
    "#Load datasets (model evaluation)\n",
    "#dftrain = pd.read_csv('data/dftrain_26_2sd.csv')\n",
    "#dftest = pd.read_csv('.data/dftest_26_2sd.csv')\n",
    "\n",
    "x[:,:,:3] = (x[:,:,:3] - np.median(x[:,:,:3], axis=1, keepdims=True))\n",
    "\n",
    "idx_diccio = {k:v for v,k in enumerate(df['snumat_id'])}\n",
    "idx_test = [idx_diccio[sample] for sample in dftest['snumat_id']]\n",
    "xtest = x[idx_test]\n",
    "ytest = y[idx_test]\n",
    "\n",
    "for row in range(xtest.shape[0]):\n",
    "    xtest[row] = xtest[row, np.lexsort((xtest[row,:,0], xtest[row,:,1], xtest[row,:,2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913063ce",
   "metadata": {
    "id": "913063ce",
    "outputId": "db1c7d8e-cf52-40ec-e169-06521ab97c1b"
   },
   "outputs": [],
   "source": [
    "xtest.shape, xeconf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eb65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a trained model \n",
    "#nn = tf.keras.models.load_model('models/nn_conv_23_2sd.keras', custom_objects={'ProcessTensor': ProcessTensor})\n",
    "#nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88ab82",
   "metadata": {
    "id": "8a88ab82",
    "outputId": "c1ed033f-cf09-4756-fbea-b7597a00ca90"
   },
   "outputs": [],
   "source": [
    "ptest = nn.predict([xtest, tf.repeat(xeconf[None,...], xtest.shape[0], axis=0)], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664f7c7",
   "metadata": {
    "id": "7664f7c7",
    "outputId": "a072597f-d2a2-440a-a926-9decc4c2bce0"
   },
   "outputs": [],
   "source": [
    "ptest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2ef5c",
   "metadata": {
    "id": "46e2ef5c",
    "outputId": "89281466-4688-45e8-87eb-da01a76e0492"
   },
   "outputs": [],
   "source": [
    "print('MAE:', abs(ytest[:,:4]-ptest[:,:4]).mean(axis=0))\n",
    "print('RMSE:', ((ytest[:,:4]-ptest[:,:4])**2).mean(axis=0)**0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b8c7f",
   "metadata": {
    "id": "763b8c7f",
    "outputId": "4865ead0-6af5-4744-ffd5-6533fb823039"
   },
   "outputs": [],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa98a6",
   "metadata": {
    "id": "20fa98a6",
    "outputId": "1c801d2c-65c1-46cb-df7b-0cced825050f"
   },
   "outputs": [],
   "source": [
    "for gap in range(4):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(ytest[:,gap], ptest[:,gap], color='blue', marker='x', alpha=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range(4):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(ytest[:,item],ptest[:,item], s=10, color='purple', alpha=0.5)\n",
    "    plt.grid()\n",
    "    plt.xlabel(r'actual band gap (eV)')\n",
    "    plt.ylabel(r'predicted bandgap (eV)')\n",
    "    #plt.plot(np.arange(-1,7), np.arange(-1,7), linewidth=1, color='black')\n",
    "    plt.title('Actual vs Predicted Values')\n",
    "# Plot histograms of actual and predicted values\n",
    "    ytest_plot = ytest[:,item]\n",
    "    ptest_plot = ptest[:,item]\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(ytest_plot, bins=200, color='blue')\n",
    "    plt.hist(ptest_plot, bins=200, color='red', alpha=0.5)\n",
    "    plt.title('Histogram of Actual and Predicted Values')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(['Actual', 'Predicted'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fc823",
   "metadata": {
    "id": "480fc823"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1e289",
   "metadata": {
    "id": "9ea1e289",
    "outputId": "de4c2ffe-6788-4871-87c5-507d80f13a04"
   },
   "outputs": [],
   "source": [
    "precision_recall_fscore_support(ytest[:,-1].astype(int), (1 + np.exp(-ptest[:,-1]))**-1 >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82312f8",
   "metadata": {
    "id": "f82312f8",
    "outputId": "51a408d0-b5ab-4ceb-cddc-7640c3dc23ef"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(ytest[:,-1].astype(int), (1 + np.exp(-ptest[:,-1]))**-1 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_df= pd.read_csv(f'data/{model_name}_losses.csv')\n",
    "epochs = losses_df.index \n",
    "train_data = losses_df['train']\n",
    "test_data = losses_df['test']\n",
    "plt.plot(epochs, train_data, label='Train')\n",
    "plt.plot(epochs, test_data, label='Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5121eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model architecture visualization\n",
    "!netron nn_conv_27_2sd.keras"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TF2.17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
